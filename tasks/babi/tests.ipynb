{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recurrent_controller import RecurrentController\n",
    "from dnc.dnc import DNC\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def llprint(message):\n",
    "    sys.stdout.write(message)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def load(path):\n",
    "    return pickle.load(open(path, 'rb'))\n",
    "\n",
    "def onehot(index, size):\n",
    "    vec = np.zeros(size, dtype=np.float32)\n",
    "    vec[index] = 1.0\n",
    "    return vec\n",
    "\n",
    "def prepare_sample(sample, target_code, word_space_size):\n",
    "    input_vec = np.array(sample[0]['inputs'], dtype=np.float32)\n",
    "    output_vec = np.array(sample[0]['inputs'], dtype=np.float32)\n",
    "    seq_len = input_vec.shape[0]\n",
    "    weights_vec = np.zeros(seq_len, dtype=np.float32)\n",
    "\n",
    "    target_mask = (input_vec == target_code)\n",
    "    output_vec[target_mask] = sample[0]['outputs']\n",
    "    weights_vec[target_mask] = 1.0\n",
    "\n",
    "    input_vec = np.array([onehot(code, word_space_size) for code in input_vec])\n",
    "    output_vec = np.array([onehot(code, word_space_size) for code in output_vec])\n",
    "\n",
    "    return (\n",
    "        np.reshape(input_vec, (1, -1, word_space_size)),\n",
    "        np.reshape(output_vec, (1, -1, word_space_size)),\n",
    "        seq_len,\n",
    "        np.reshape(weights_vec, (1, -1, 1))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ckpts_dir = './checkpoints/'\n",
    "lexicon_dictionary = load('./data/en/lexicon-dict.pkl')\n",
    "question_code = lexicon_dictionary[\"?\"]\n",
    "target_code = lexicon_dictionary[\"-\"]\n",
    "test_files = []\n",
    "\n",
    "for entryname in os.listdir('./data/en/test/'):\n",
    "    entry_path = os.path.join('./data/en/test/', entryname)\n",
    "    if os.path.isfile(entry_path):\n",
    "        test_files.append(entry_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa14_time-reasoning_test.txt.pkl ... 0/200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa14_time-reasoning_test.txt.pkl ... 67.600% Error Rate.\n",
      "qa4_two-arg-relations_test.txt.pkl ... 29.600% Error Rate.\n",
      "qa8_lists-sets_test.txt.pkl ... 32.200% Error Rate.\n",
      "qa2_two-supporting-facts_test.txt.pkl ... 61.700% Error Rate.\n",
      "qa9_simple-negation_test.txt.pkl ... 35.300% Error Rate.\n",
      "qa15_basic-deduction_test.txt.pkl ... 70.330% Error Rate.\n",
      "qa17_positional-reasoning_test.txt.pkl ... 48.040% Error Rate.\n",
      "qa6_yes-no-questions_test.txt.pkl ... 35.335% Error Rate.\n",
      "qa16_basic-induction_test.txt.pkl ... 53.486% Error Rate.\n",
      "qa13_compound-coreference_test.txt.pkl ... 6.400% Error Rate.\n",
      "qa19_path-finding_test.txt.pkl ... 89.841% Error Rate.\n",
      "qa10_indefinite-knowledge_test.txt.pkl ... 46.200% Error Rate.\n",
      "qa1_single-supporting-fact_test.txt.pkl ... 51.500% Error Rate.\n",
      "qa12_conjunction_test.txt.pkl ... 39.239% Error Rate.\n",
      "qa18_size-reasoning_test.txt.pkl ... 9.218% Error Rate.\n",
      "qa11_basic-coreference_test.txt.pkl ... 32.700% Error Rate.\n",
      "qa7_counting_test.txt.pkl ... 24.152% Error Rate.\n",
      "qa20_agents-motivations_test.txt.pkl ... 10.521% Error Rate.\n",
      "qa5_three-arg-relations_test.txt.pkl ... 54.500% Error Rate.\n",
      "qa3_three-supporting-facts_test.txt.pkl ... 72.582% Error Rate.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "incomplete format",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-47592e57c7b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mllprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r%s ... %.3f%% Error Rate.\\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Mean Error Rate: %.3f%\"\u001b[0m \u001b[1;33m%\u001b[0m  \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_tasks_results\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Failed Tasks (> 5%): %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_tasks_results\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: incomplete format"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        \n",
    "        ncomputer = DNC(\n",
    "            RecurrentController,\n",
    "            input_size=len(lexicon_dictionary),\n",
    "            output_size=len(lexicon_dictionary),\n",
    "            max_sequence_length=1920,\n",
    "            memory_words_num=256,\n",
    "            memory_word_size=64,\n",
    "            memory_read_heads=4,\n",
    "        )\n",
    "        \n",
    "        ncomputer.restore(session, ckpts_dir, 'step-30004')\n",
    "        \n",
    "        outputs, _ = ncomputer.get_outputs()\n",
    "        softmaxed = tf.nn.softmax(outputs)\n",
    "        \n",
    "        all_tasks_results = []\n",
    "        for test_file in test_files:\n",
    "            test_data = load(test_file)\n",
    "            task_name = os.path.basename(test_file)\n",
    "            counter = 0\n",
    "            results = []\n",
    "            \n",
    "            llprint(\"%s ... %d/%d\" % (task_name, counter, len(test_data)))\n",
    "            \n",
    "            for story in test_data:\n",
    "                astory = np.array(story['inputs'])\n",
    "                questions_indecies = np.argwhere(astory == question_code)\n",
    "                questions_indecies = np.reshape(questions_indecies, (-1,))\n",
    "                target_mask = (astory == target_code)\n",
    "                \n",
    "                desired_answers = np.array(story['outputs'])\n",
    "                input_vec, _, seq_len, _ = prepare_sample([story], target_code, len(lexicon_dictionary))\n",
    "                softmax_output = session.run(softmaxed, feed_dict={\n",
    "                        ncomputer.input_data: input_vec,\n",
    "                        ncomputer.sequence_length: seq_len\n",
    "                })\n",
    "                softmax_output = np.squeeze(softmax_output, axis=0)\n",
    "                given_answers = np.argmax(softmax_output[target_mask], axis=1)\n",
    "                \n",
    "                answers_cursor = 0\n",
    "                for question_indx in questions_indecies:\n",
    "                    question_grade = []\n",
    "                    targets_cursor = question_indx + 1\n",
    "                    while targets_cursor < len(astory) and astory[targets_cursor] == target_code:\n",
    "                        question_grade.append(given_answers[answers_cursor] == desired_answers[answers_cursor])\n",
    "                        answers_cursor += 1\n",
    "                        targets_cursor += 1\n",
    "                    results.append(np.prod(question_grade))\n",
    "                \n",
    "                counter += 1\n",
    "                llprint(\"\\r%s ... %d/%d\" % (task_name, counter, len(test_data)))\n",
    "                \n",
    "            error_rate = 1. - np.mean(results)\n",
    "            all_tasks_results.append(error_rate)\n",
    "            llprint(\"\\r%s ... %.3f%% Error Rate.\\n\" % (task_name, error_rate * 100))\n",
    "        \n",
    "        print \"Mean Error Rate: %.3f%%\" %  (np.mean(all_tasks_results) * 100)\n",
    "        print \"Failed Tasks (> 5%%): %d\" % (np.sum(all_tasks_results > 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
