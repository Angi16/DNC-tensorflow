{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from recurrent_controller import RecurrentController\n",
    "from dnc.dnc import DNC\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def llprint(message):\n",
    "    sys.stdout.write(message)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def load(path):\n",
    "    return pickle.load(open(path, 'rb'))\n",
    "\n",
    "def onehot(index, size):\n",
    "    vec = np.zeros(size, dtype=np.float32)\n",
    "    vec[index] = 1.0\n",
    "    return vec\n",
    "\n",
    "def prepare_sample(sample, target_code, word_space_size):\n",
    "    input_vec = np.array(sample[0]['inputs'], dtype=np.float32)\n",
    "    output_vec = np.array(sample[0]['inputs'], dtype=np.float32)\n",
    "    seq_len = input_vec.shape[0]\n",
    "    weights_vec = np.zeros(seq_len, dtype=np.float32)\n",
    "\n",
    "    target_mask = (input_vec == target_code)\n",
    "    output_vec[target_mask] = sample[0]['outputs']\n",
    "    weights_vec[target_mask] = 1.0\n",
    "\n",
    "    input_vec = np.array([onehot(code, word_space_size) for code in input_vec])\n",
    "    output_vec = np.array([onehot(code, word_space_size) for code in output_vec])\n",
    "\n",
    "    return (\n",
    "        np.reshape(input_vec, (1, -1, word_space_size)),\n",
    "        np.reshape(output_vec, (1, -1, word_space_size)),\n",
    "        seq_len,\n",
    "        np.reshape(weights_vec, (1, -1, 1))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ckpts_dir = './checkpoints/'\n",
    "lexicon_dictionary = load('./data/en-10k/lexicon-dict.pkl')\n",
    "target_code = lexicon_dictionary[\"-\"]\n",
    "test_files = []\n",
    "\n",
    "for entryname in os.listdir('./data/en-10k/test/'):\n",
    "    entry_path = os.path.join('./data/en-10k/test/', entryname)\n",
    "    if os.path.isfile(entry_path):\n",
    "        test_files.append(entry_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa14_time-reasoning_test.txt.pkl ... 0/200"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qa14_time-reasoning_test.txt.pkl ... 73.600% Error Rate.\n",
      "qa4_two-arg-relations_test.txt.pkl ... 31.900% Error Rate.\n",
      "qa8_lists-sets_test.txt.pkl ... 47.895% Error Rate.\n",
      "qa2_two-supporting-facts_test.txt.pkl ... 66.500% Error Rate.\n",
      "qa9_simple-negation_test.txt.pkl ... 32.200% Error Rate.\n",
      "qa15_basic-deduction_test.txt.pkl ... 75.425% Error Rate.\n",
      "qa17_positional-reasoning_test.txt.pkl ... 8/125"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-064b5c6ad0df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m                 softmax_output = session.run(softmaxed, feed_dict={\n\u001b[0;32m     34\u001b[0m                         \u001b[0mncomputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minput_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                         \u001b[0mncomputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m                 })\n\u001b[0;32m     37\u001b[0m                 \u001b[0msoftmax_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoftmax_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 717\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    718\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 915\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    916\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 965\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    970\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    973\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        \n",
    "        ncomputer = DNC(\n",
    "            RecurrentController,\n",
    "            input_size=len(lexicon_dictionary),\n",
    "            output_size=len(lexicon_dictionary),\n",
    "            max_sequence_length=1920,\n",
    "            memory_words_num=256,\n",
    "            memory_word_size=32,\n",
    "            memory_read_heads=4,\n",
    "        )\n",
    "        \n",
    "        ncomputer.restore(session, ckpts_dir, 'step-20842')\n",
    "        \n",
    "        outputs, _ = ncomputer.get_outputs()\n",
    "        softmaxed = tf.nn.softmax(outputs)\n",
    "        \n",
    "        all_tasks_results = []\n",
    "        for test_file in test_files:\n",
    "            test_data = load(test_file)\n",
    "            task_name = os.path.basename(test_file)\n",
    "            counter = 0\n",
    "            results = []\n",
    "            \n",
    "            llprint(\"%s ... %d/%d\" % (task_name, counter, len(test_data)))\n",
    "            \n",
    "            for story in test_data:\n",
    "                target_mask = (np.array(story['inputs']) == target_code)\n",
    "                desired_answers = np.array(story['outputs'])\n",
    "                input_vec, _, seq_len, _ = prepare_sample([story], target_code, len(lexicon_dictionary))\n",
    "                softmax_output = session.run(softmaxed, feed_dict={\n",
    "                        ncomputer.input_data: input_vec,\n",
    "                        ncomputer.sequence_length: seq_len\n",
    "                })\n",
    "                softmax_output = np.squeeze(softmax_output, axis=0)\n",
    "                given_answers = np.argmax(softmax_output[target_mask], axis=1)\n",
    "                grades = (given_answers == desired_answers)\n",
    "                results.extend(grades)\n",
    "                \n",
    "                counter += 1\n",
    "                llprint(\"\\r%s ... %d/%d\" % (task_name, counter, len(test_data)))\n",
    "                \n",
    "            error_rate = 1. - np.mean(results)\n",
    "            all_tasks_results.append(error_rate)\n",
    "            llprint(\"\\r%s ... %.3f%% Error Rate.\\n\" % (task_name, error_rate * 100))\n",
    "        \n",
    "        print \"Mean Error Rate: %.3f%\" %  (np.mean(all_tasks_results) * 100)\n",
    "        print \"Failed Tasks (> 5%): %d\" % (np.sum(all_tasks_results > 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
